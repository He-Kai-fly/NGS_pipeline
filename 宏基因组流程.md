### Metagenomic analysis

```shell
#!bin/sh
R1=C2_clean1.fastq
R2=C2_clean2.fastq
b=${R1%_*q} #保留变量
cog=/home/pub_guest/hekai/samples_12data/CLEAN_DATA/function/COG/
EGGNOG=/home/pub_guest/hekai/soft_ware/Eggnog/eggnog-mapper-1.0.3/data/eggnog_proteins.dmnd
NR=/home/pub_guest/hekai/samples_12data/annotate/nr.tax.dmnd
sliva=/home/pub_guest/hekai/db/sliva_database/
script=/home/pub_guest/hekai/script/
host=/home/pub_guest/hekai/samples_12data/reference/genome/GCF_000003025.6_Sscrofa11.1_genomic.fna
bwa mem -t 4 -M ${host} ${R1} ${R2} | /usr/local/bin/samtools view -bS > ${b}_bwa.bam  #比对宿主
/usr/local/bin/samtools flagstats ${b}_bwa.bam>${b}_mapping_host.txt   
/usr/local/bin/samtools view -b -f12 -F256 ${b}_bwa.bam > ${b}_f12.bam #提取未比对上的
/usr/local/bin/samtools sort -@ 4 -O bam -n -o ${b}_f12_sorted.bam -T ${b}_f12_sort ${b}_f12.bam #排序
rm ${b}_f12.bam ${b}_bwa.bam 
bedtools bamtofastq -i ${b}_f12_sorted.bam -fq clean1_${b}.fastq -fq2 clean2_${b}.fastq #提取双端序列
rm ${b}_f12_sorted.bam ${R1} ${R2}
```

#### 基因组装、比对、预测、定量、物种及功能注释

```shell
megahit -t4 -m0.95 --min-contig-len 500 -1 clean1_${b}.fastq -2 clean2_${b}.fastq -o ${b}_megahit.asm #组装
cd ${b}_megahit.asm
python3.6 ${script}fasta_stat.py -i final.contigs.fa -o ${b}_contig_stat.txt
rm -r intermediate_contigs/
bwa index final.contigs.fa  #建立索引
bwa mem -t 4 -M final.contigs.fa  ../clean1_${b}.fastq  ../clean2_${b}.fastq |/usr/local/bin/samtools view -bS > ${b}_mapping.bam  #比对contigs
/usr/local/bin/samtools flagstats ${b}_mapping.bam > ${b}_used.txt
rm ${b}_mapping.bam
cd ..
mkdir prediction && cd prediction
prodigal -p meta -m -d ${b}_nucleotide_seq.fasta -i ../${b}_megahit.asm/final.contigs.fa #基因预测
perl ${script}retain_long_sequences.pl 100 ${b}_nucleotide_seq.fasta > ${b}_100great.fasta # 提取>100bp的核酸序列
cd-hit-est -i ${b}_100great.fasta -o ${b}_NR100nl.fasta -c 0.95 -n 7 -T 0 -M 0 -aS 0.9 # 去冗余
transeq -table 11 -sequence ${b}_NR100nl.fasta -outseq ${b}_NR100pro.fasta -trim Y # 翻译为蛋白
sed -i 's/_1$//' ${b}_NR100pro.fasta
rm ${b}_100great.fasta  ${b}_nucleotide_seq.fasta ${b}_NR100nl.fasta.clstr
salmon index -t ${b}_NR100nl.fasta -p 9 -k 31 -i ./index
salmon quant --validateMappings -i ./index -l A -p 3  --meta -1 ../clean1_${b}.fastq -2 ../clean2_${b}.fastq -o ${b}.quant #基因定量
/home/pub_guest/hekai/soft_ware/Diamond/bin/diamond blastp --db ${NR} -q ${b}_NR100pro.fasta --outfmt 6 qseqid sseqid pident length qlen mismatch gapopen qstart qend evalue bitscore salltitles  -e 1e-5 -o ${b}_NR.out #NR库注释
less ${b}_NR.out | awk '!a[$1]++{print}'|cut -f 12 |sed 's/.*\[//g;s/\].*//g' > annotion.txt
less ${b}_NR.out | awk '!a[$1]++{print}'|cut -f 1 >id.txt
taxonkit name2taxid  annotion.txt >scientific_name_taxid.txt
python ${script}pipei.py annotion.txt  scientific_name_taxid.txt  3.txt
paste id.txt  3.txt |awk -F "\t" '$3!=null{print $0}' > id_taxid.txt
less id_taxid.txt|cut -f 3|taxonkit lineage |taxonkit reformat -f "{k};{p};{c};{o};{f};{g};{s}"|cut -f 3 >full_ano.txt
paste id_taxid.txt full_ano.txt | cut -f 1,4 |grep "Bacteria"|sed 's/ /_/g;s/;/\t/g'|awk -F "\t" '$3!=null{print $0}'|sed '1i\qq'|awk '{FS=OFS="\t"}{if($4=="")$4="unclassfied_p_"$3}{if($5=="")$5="unclassfied_p_"$3}{if($6=="")$6="unclassfied_p_"$3}{if($7=="")$7="unclassfied_p_"$3}{if($8=="")$8="unclassfied_p_"$3}1'|sed '1d'|awk  '{print $1"\t""k_"$2"\t""p_"$3"\t""c_"$4"\t""o_"$5"\t""f_"$6"\t""g_"$7"\t""s_"$8}' > final_ano.txt #通过taxonkit软件得到lineage
rm annotion.txt id.txt scientific_name_taxid.txt 3.txt full_ano.txt ${b}_NR.out id_taxid.txt
cd ../
mkdir -p annotion/COG
cd annotion/COG
/home/pub_guest/hekai/soft_ware/Eggnog/eggnog-mapper-1.0.3/bin/diamond blastp --db ${EGGNOG} --query ../../prediction/${b}_NR100pro.fasta --out eggNOG.tab --outfmt 6 --sensitive --max-target-seqs 20 --evalue 1e-5 --id 30  #EGGNOG注释
less eggNOG.tab |awk '!a[$1]++{print}'|cut -f 1,2,11,12 > eggNOG.emapper.seed_orthologs
python2  /home/pub_guest/hekai/soft_ware/Eggnog/eggnog-mapper-1.0.3/emapper.py --annotate_hits_table  ./eggNOG.emapper.seed_orthologs -o ${b}_eggNOG   --output_dir .
```

#### 物种丰度统计

```shell
script=/home/pub_guest/hekai/script/
abundance=/home/pub_guest/hekai/samples_12data/CLEAN_DATA/$1/prediction/nr/
salmon=/home/pub_guest/hekai/samples_12data/CLEAN_DATA/$1/prediction/$1.quant/
kegg=/home/pub_guest/hekai/samples_12data/CLEAN_DATA/$1/annotion/KEGG/
cog=/home/pub_guest/hekai/samples_12data/CLEAN_DATA/$1/annotion/EGGNOG/
less  ${salmon}quant.sf | sed '1d'|cut -f 1,2,5| awk '{a=$3/$2}{print $1"\t"$2"\t"$3"\t"a}'|cut -f 1,4|awk '{a[NR]=$2;sum+=$2}END{for(i=1;i<=NR;i++)printf "%.6f\n", a[i]*10^6/sum}' > 1.txt
less  ${salmon}quant.sf | sed '1d'|cut -f 1 >2.txt
paste 2.txt 1.txt > $1_abundance.txt
mv $1_abundance.txt ${salmon}
rm 1.txt 2.txt
cd nr_abun
less ${abundance}final_ano.txt |cut -f 1 > 3.txt
python3 ${script}pipei.py 3.txt ${salmon}$1_abundance.txt $1_nr_abun.txt
paste /home/pub_guest/hekai/samples_12data/CLEAN_DATA/$1/prediction/nr/final_ano.txt $1_nr_abun.txt | cut -f 3,10 | awk '{pop[$1]+=$2}END{for (name in pop)print name "\t"pop[name]}'|sort -k2,2nr > $1_nr_Phylum.txt
paste /home/pub_guest/hekai/samples_12data/CLEAN_DATA/$1/prediction/nr/final_ano.txt $1_nr_abun.txt | cut -f 4,10 | awk '{pop[$1]+=$2}END{for (name in pop)print name "\t"pop[name]}'|sort -k2,2nr > $1_nr_Class.txt
paste /home/pub_guest/hekai/samples_12data/CLEAN_DATA/$1/prediction/nr/final_ano.txt $1_nr_abun.txt | cut -f 5,10 | awk '{pop[$1]+=$2}END{for (name in pop)print name "\t"pop[name]}'|sort -k2,2nr > $1_nr_Order.txt
paste /home/pub_guest/hekai/samples_12data/CLEAN_DATA/$1/prediction/nr/final_ano.txt $1_nr_abun.txt | cut -f 6,10 | awk '{pop[$1]+=$2}END{for (name in pop)print name "\t"pop[name]}'|sort -k2,2nr > $1_nr_Family.txt
paste /home/pub_guest/hekai/samples_12data/CLEAN_DATA/$1/prediction/nr/final_ano.txt $1_nr_abun.txt | cut -f 7,10 | awk '{pop[$1]+=$2}END{for (name in pop)print name "\t"pop[name]}'|sort -k2,2nr > $1_nr_Genu.txt
paste /home/pub_guest/hekai/samples_12data/CLEAN_DATA/$1/prediction/nr/final_ano.txt $1_nr_abun.txt | cut -f 8,10 | awk '{pop[$1]+=$2}END{for (name in pop)print name "\t"pop[name]}'|sort -k2,2nr > $1_nr_Species.txt
rm 3.txt $1_nr_abun.txt
```

#### Cog丰度统计

```shell
#!usr/bin/sh
script=/home/pub_guest/hekai/script/
salmon=/home/pub_guest/hekai/samples_12data/CLEAN_DATA/$1/prediction/$1.quant/
less $1_eggNOG.emapper.annotations|cut -f 1,9,10,12,13 |awk '$2=="bactNOG[38]"||$2=="NOG[107]"{print}'|awk '$4!=null{print $0}'|cut -f 1,3,4,5|sed 's/\t.*,/\t/;s/@NOG//'|awk 'BEGIN{FS=OFS="\t";}{print $2,$3,$4,$1}'|sed -n '/^C/p' > 1.txt
less 1.txt | cut -f 4 >id.txt
python3  ${script}pipei.py id.txt ${salmon}$1_abundance.txt $1_cog_abun.txt
paste 1.txt $1_cog_abun.txt |cut -f 1,6|awk '{pop[$1]+=$2}END{for(name in pop)print name "\t"pop[name]}' > $1_COG_number.txt
paste 1.txt $1_cog_abun.txt |cut -f 2,6|awk '{pop[$1]+=$2}END{for(name in pop)print name "\t"pop[name]}' > $1_COG_fun.txt
rm 1.txt id.txt $1_cog_abun.txt
perl ../../script/merge.pl D1_COG_fun.txt D2_COG_fun.txt D3_COG_fun.txt D4_COG_fun.txt D5_COG_fun.txt D6_COG_fun.txt H1_COG_fun.txt H2_COG_fun.txt H3_COG_fun.txt H4_COG_fun.txt H5_COG_fun.txt H6_COG_fun.txt > COG_fun.txt
perl ../../script/merge.pl D1_COG_number.txt D2_COG_number.txt D3_COG_number.txt D4_COG_number.txt D5_COG_number.txt D6_COG_number.txt H1_COG_number.txt H2_COG_number.txt H3_COG_number.txt H4_COG_number.txt H5_COG_number.txt H6_COG_number.txt > COG_number.txt
```

### KEGG注释 统计分析(for循环批量处理)

#### Moudle丰度差异

1. 根据KO表在KEGG官网中Mapper中的Reconstruct Pathway 得到Moudle的匹配信息.
2. 复制下来根据perl脚本得到对应表，R中将注释信息添加对应起来.

```

```





### PATHWAY丰度差异

```shell
less ${kegg}gene_anno.txt | sed '1d' | cut -f 1 > $1_kegg_id.txt
python3 ${script}pipei.py $1_kegg_id.txt ${salmon}$1_abundance.txt $1_kegg_abun.txt
paste $1 ${b}ko_abu.txt | cut -f 2,4 > ${b}_KO.txt
less ${b}_KO.txt | awk '{pop[$1]+=$2}END{for (name in pop)print name "\t"pop[name]}' > ${b}_KOa.txt#批量
先得到每个样品KO丰度 再整合
perl ${script}merge.pl D1_KO.txt D2_KO.txt D3_KO.txt D4_KO.txt D5_KO.txt D6_KO.txt H1_KO.txt H2_KO.txt H3_KO.txt H4_KO.txt H5_KO.txt H6_KO.txt |sed '1d'|sed 's/:/\t/'|sed '1i\KO\tD1\tD2\tD3\tD4\tD5\tD6\tH1\tH2\tH3\t\H4\t\H5\tH6' | sed 's/_/ /g' > KO.txt
```



#### 筛选过滤数据（一般平均相对丰度>0.1%）

基于KASS拿到KO表后先转换为相对丰度，再根据要求进行数据过滤

```R
#过滤数据
phylum <- apply(kegg1_abundance, 2, function(x){x/sum(x)})#计算百分比化
phylum_filter <- data.frame(phylum[which(apply(phylum, 1, function(x){mean(x)})
>0.001),], check.names=F) #筛选平均丰度>0.001的数据
# phylum_filter <-data.frame(phylum[apply(phylum,1,max)>0.001,])#去除至少有1个样品中大于%0.1的物种
#补充
count <- 1
tab_min <- data.frame(tab[which(apply(tab, 1, function(x){mean(x)})
                                >count),], check.names=F)#设置1为阈值，过滤平均丰度小于1的物种
cutoff = .5
tab_d5 <- data.frame(tab[which(apply(tab, 1, function(x){length(which
                                                                (x!= 0))/length(x)}) > cutoff),])
#设置0.5为阈值，过滤在一半或者大于一半样品中丰度为0的物种
count = 500
tab_c500 <- data.frame(tab[which(apply(tab, 1, function(x){sum(x)})
                                 > count),])#过滤物种所有样品中总丰度小于500的物种
tab_perc <- apply(tab[,1:ncol(phylum_perc)-1], 2, function(x){x/sum(x)})#有时需要去除最后一行
```

###### 基于R分析

```
library(dplyr)
library(ggplot2)
rm(list = ls())
options(digits = 3)
kegg_anno <- read.table('11.txt', sep = '\t', stringsAsFactors = FALSE, check.names = FALSE,header = T)  #读取KEGG解析层级文件(Python脚本获得)
gene <- read.delim('kegg_4.txt', sep = '\t', row.names = 1,stringsAsFactors = FALSE, check.names = FALSE) #读取KO相对丰度表
gene$Gene_level <- rownames(gene)
tax4fun_pathway <- merge(kegg_anno, gene, by = 'Gene_level') 
write.table(tax4fun_pathway, 'final_kegg.txt', row.names = FALSE, sep = '\t', quote = FALSE)
## 第1层级功能丰度 统计求和
KEGG1 <- select(tax4fun_pathway,Pathway1_level,D1:H6)
by_kegg1 <- group_by(KEGG1,Pathway1_level)
kegg1_abundance <- summarize(by_kegg1,
                   D1 = sum(D1),
                   D2 = sum(D2),
                   D3 = sum(D3),
                   D4 = sum(D4),
                   D5 = sum(D5),
                   D6 = sum(D6),
                   H1 = sum(H1),
                   H2 = sum(H2),
                   H3 = sum(H3),
                   H4 = sum(H4),
                   H5 = sum(H5),
                   H6 = sum(H6)
)
write.table(kegg1_abundance, 'kegg1_abun.txt', row.names = FALSE, sep = '\t', quote = FALSE)
## 第2层级功能丰度
KEGG2 <- select(tax4fun_pathway,Pathway2_level,D1:H6)
by_kegg2 <- group_by(KEGG2,Pathway2_level)
kegg2_abundance <- summarize(by_kegg2,
                             D1 = sum(D1),
                             D2 = sum(D2),
                             D3 = sum(D3),
                             D4 = sum(D4),
                             D5 = sum(D5),
                             D6 = sum(D6),
                             H1 = sum(H1),
                             H2 = sum(H2),
                             H3 = sum(H3),
                             H4 = sum(H4),
                             H5 = sum(H5),
                             H6 = sum(H6)
)
write.table(kegg2_abundance, 'kegg2_abun.txt', row.names = FALSE, sep = '\t', quote = FALSE)
##代谢通路功能丰度
KEGG3 <- select(tax4fun_pathway,Pathway3_level,D1:H6)
by_kegg3 <- group_by(KEGG3,Pathway3_level)
kegg3_abundance <- summarize(by_kegg3,
                             D1 = sum(D1),
                             D2 = sum(D2),
                             D3 = sum(D3),
                             D4 = sum(D4),
                             D5 = sum(D5),
                             D6 = sum(D6),
                             H1 = sum(H1),
                             H2 = sum(H2),
                             H3 = sum(H3),
                             H4 = sum(H4),
                             H5 = sum(H5),
                             H6 = sum(H6)
)
write.table(kegg3_abundance, 'kegg3_abun.txt', row.names = FALSE, sep = '\t', quote = FALSE)
以上代码获得各个水平的丰度表

```

![image-20200211150753340](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200211150753340.png)

###  另一种形式统计求和(以KEGG第一层级为例子,其它类似)

```R
library(reshape2)
library(doBy)

group <- read.delim('sample.txt', sep = '\t', stringsAsFactors = FALSE, check.names = FALSE)#读取分组文件
names(group)[1] <- 'variable'
#haha <- tax4fun_pathway[c(group$variable, 'Pathway1_level')] # 另一种选择列的方式(比较方便)

#另一种统计求和的方式
KEGG1_new <- melt(kegg1_abundance, id = 'Pathway1_level')
KEGG1_new <- summaryBy(value~variable+Pathway1_level, KEGG1_new, FUN = sum)
KEGG1_new <- merge(KEGG1_new, group, by = 'variable')

#计算标准差、标准误
se <- function(x) sd(x) / (length(x))^0.5
pathway_stat <- summaryBy(value.sum~group+Pathway1_level, KEGG1_new, FUN = c(mean, sd, se))

##添加注释 将前几层级的注释添加 
kegg_anno_2 <- kegg_anno[!duplicated(kegg_anno$Pathway1), ][-c(3:7)] #此步基于特定列去重
pathway_stat <- merge(pathway_stat, kegg_anno_2, by = 'Pathway1_level', all.x = TRUE) 

```

```
#可选进行显著性差异分析，这里直接使用 wilcoxon 秩和检验
Pathway1_level <- unique(KEGG1_new$Pathway1_level)
for (i in Pathway1_level) {
  tax4fun_pathway_1_i <- subset(KEGG1_new, Pathway1_level == i)
  test <- wilcox.test(value.sum~group, tax4fun_pathway_1_i)
  line_t <- which(pathway_stat$Pathway1_level == i & pathway_stat$group == 'H')
  pathway_stat[line_t,'p_value'] <- test$p.value
  if (test$p.value < 0.05 & test$p.value >= 0.01) {
    pathway_stat[line_t,'sign'] <- '*'
  }
  if (test$p.value < 0.01 & test$p.value >= 0.001) {
    pathway_stat[line_t,'sign'] <- '**'
  }
  if (test$p.value < 0.001) {
    pathway_stat[line_t,'sign'] <- '***'
  }
}
write.table(pathway_stat, 'pathway1_stat.txt', row.names = FALSE, sep = '\t', quote = FALSE)
可选查看“pathway_stat”。两两比较后（control组和treat组），我们将计算得到的显著性p值添加在二者之一的“treat”行中（“control”行不再添加重复的p值，R程序自动记为NA），同时在该行根据显著性添加“*”标记（同样地，“control”行不再添加）
其中，p≥0.05，不标记“*”；0.01≤p＜0.05，标记“*”；0.001≤p＜0.00，标记“**”；p＜0.001，标记“***”。获得如下形式表格
```



![image-20200211150914887](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200211150914887.png)



###  基于上表使用 ggplot2 作图

```R
pathway_stat$value.sum.mean <- 100 * pathway_stat$value.sum.mean
pathway_stat$value.sum.sd <- 100 * pathway_stat$value.sum.sd

pathway2_plot <- ggplot(pathway_stat, aes(Pathway1_level, value.sum.mean, fill = group)) +
  geom_col(position = 'dodge', width = 0.8, colour = 'black', size = 0.05) +  #“dodge 柱状图”样式
  geom_errorbar(aes(ymin = value.sum.mean - value.sum.sd, ymax = value.sum.mean + value.sum.sd), size = 0.05, width = .35, position = position_dodge(width = .8)) +  #添加误差线（均值±标准差）
  scale_fill_manual(values = c('red', 'blue')) +  #填充颜色
  theme(legend.title = element_blank(), legend.position = c(0.9, 0.9)) +  #去除图例标题，调整图例位置
  coord_flip() +  #横、纵坐标轴反转
  theme(panel.grid = element_blank(), panel.background = element_rect(fill = 'transparent',  color = 'black')) +  #去除默认的背景框
  geom_text(aes(label = sign, y = value.sum.mean + value.sum.sd + 0.5), size = 6, position = position_dodge(0.8)) +  #添加显著性标记“*”
  labs(x = 'KEGG pathway2', y = 'Relative Abundance (%)')  #坐标轴标题

pathway2_plot
ggsave('Kegg_pathway2.pdf', pathway2_plot, width = 8, height = 10)
ggsave('Kegg_pathway2.png', pathway2_plot, width = 8, height = 10)


```

![image-20200211153425852](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200211153425852.png)

### 计算P值（含多重矫正）

```
###  另一种处理方式
#读取KEGG1数据框 注意设置rownames = 1
gene <- read.table('kegg1_abun.txt', sep = '\t', row.names = 1, header = TRUE, stringsAsFactors = FALSE, check.names = FALSE)
group <- read.table('sample.txt', sep = '\t', header = TRUE, stringsAsFactors = FALSE, check.names = FALSE)
names(group)[1] <- c('sample')
result <- NULL
for (n in 1:nrow(gene)) {
  gene_n <- data.frame(t(gene[n,subset(group, group %in% c("D", "H"))$sample]))
  gene_id <- names(gene_n)[1]
  names(gene_n)[1] <- 'gene'
  gene_n$sample <- rownames(gene_n)
  gene_n <- merge(gene_n, group, by = 'sample', all.x = TRUE)
  gene_n$group <- factor(gene_n$group)
  p_value <- wilcox.test(gene~group, gene_n,exact = FALSE)$p.value
  if (!is.na(p_value) & p_value < 0.05) {
    stat <- summaryBy(gene~group, gene_n, FUN = c(mean, sd))
    result <- rbind(result, c(gene_id, as.character(stat[1,1]), stat[1,2], stat[1,3], as.character(stat[2,1]), stat[2,2], stat[2,3], p_value))
  }
}

result <- data.frame(result)
names(result) <- c('KEGG_level1', 'group1', 'mean1', 'sd1', 'group2', 'mean2', 'sd2', 'p_value')
result <- result[order(result$p_value),]  # 从小到大排序
# P.adjust  p 值校正的过程 
#先将p值那列提出转换为矩阵形式 
a <- as.matrix(result$p_value)
p_adjust <- p.adjust(a,method = 'BH',n = length(a)) # 这里使用BH方法 和fdr结果相似
result <- cbind(result,p_adjust)
write.table(result, 'pathway1_diff.txt', sep = '\t', row.names = FALSE, quote = FALSE)
获得以下形式表格
```

![image-20200211151404270](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200211151404270.png)

